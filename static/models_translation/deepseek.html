<div class="model-lang-content lang-en hidden">
    <h3 class="text-2xl font-bold mb-4">Elevate Your Intelligent Applications with DeepSeek-V3.2</h3>
    <p class="mb-4 text-gray-600 dark:text-gray-300">DeepSeek-V3.2 represents the pinnacle of efficient large language models, designed to provide enterprise-grade performance through a highly optimized Mixture-of-Experts (MoE) architecture. This model is engineered for businesses seeking a balance between sophisticated reasoning and cost-effective scalability. By integrating DeepSeek-V3.2 via our API, you gain access to a powerhouse capable of handling complex multilingual tasks, advanced code generation, and nuanced content synthesis with exceptional precision.</p>
    <p class="mb-6 text-gray-600 dark:text-gray-300">With its massive parameter scale, the model demonstrates fluid adaptability across diverse domains, ensuring that your applications remain at the forefront of the AI revolution. It offers a seamless experience that matches the output quality of industry leaders like GPT-4o, making it an ideal choice for high-throughput production environments where reliability and intelligence are paramount.</p>
    <h4 class="text-xl font-bold mb-4 text-primary">Key Technical Specifications:</h4>
    <div class="overflow-x-auto">
        <table class="w-full text-sm text-left border border-gray-200 dark:border-gray-700">
            <thead class="bg-gray-100 dark:bg-gray-800 uppercase font-bold">
                <tr><th class="px-4 py-3">Feature</th><th class="px-4 py-3">Specification</th></tr>
            </thead>
            <tbody class="divide-y divide-gray-200 dark:divide-gray-700">
                <tr><td class="px-4 py-2 font-semibold">Model Name</td><td class="px-4 py-2">DeepSeek-V3.2 (Base)</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Release Date</td><td class="px-4 py-2">December 1, 2025</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Architecture</td><td class="px-4 py-2">Multi-head Latent Attention (MLA) & DeepSeekMoE</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Total Parameters</td><td class="px-4 py-2">671 Billion</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Activated Parameters</td><td class="px-4 py-2">37 Billion (per token)</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Context Window</td><td class="px-4 py-2">128,000 Tokens</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Max Output Length</td><td class="px-4 py-2">131,072 Tokens</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Supported Modalities</td><td class="px-4 py-2">Multilingual Text, Code, Reasoning</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Inference Optimization</td><td class="px-4 py-2">Multi-Token Prediction (MTP) Technology</td></tr>
            </tbody>
        </table>
    </div>
</div>

<div class="model-lang-content lang-ar hidden">
    <h3 class="text-2xl font-bold mb-4">Ø§Ø±ØªÙ‚Ù Ø¨ØªØ·Ø¨ÙŠÙ‚Ø§ØªÙƒ Ø§Ù„Ø°ÙƒÙŠØ© Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬ DeepSeek-V3.2</h3>
    <p class="mb-4 text-gray-600 dark:text-gray-300">ÙŠÙ…Ø«Ù„ DeepSeek-V3.2 Ø°Ø±ÙˆØ© Ø§Ù„ÙƒÙØ§Ø¡Ø© ÙÙŠ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¶Ø®Ù…Ø©ØŒ Ø­ÙŠØ« ØªÙ… ØªØµÙ…ÙŠÙ…Ù‡ Ù„ØªÙ‚Ø¯ÙŠÙ… Ø£Ø¯Ø§Ø¡ Ø¨Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø¤Ø³Ø³Ø§Øª Ù…Ù† Ø®Ù„Ø§Ù„ Ø¨Ù†ÙŠØ© "Ø®Ù„ÙŠØ· Ø§Ù„Ø®Ø¨Ø±Ø§Ø¡" (MoE) Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ø¨Ø¯Ù‚Ø©. ØªÙ… Ù‡Ù†Ø¯Ø³Ø© Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø®ØµÙŠØµØ§Ù‹ Ù„Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„ØªÙŠ ØªØ¨Ø­Ø« Ø¹Ù† ØªÙˆØ§Ø²Ù† Ù…Ø«Ø§Ù„ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© ÙˆØ§Ù„ÙØ¹Ø§Ù„ÙŠØ© Ù…Ù† Ø­ÙŠØ« Ø§Ù„ØªÙƒÙ„ÙØ©. Ù…Ù† Ø®Ù„Ø§Ù„ Ø¯Ù…Ø¬ DeepSeek-V3.2 Ø¹Ø¨Ø± Ø§Ù„Ù€ API Ø§Ù„Ø®Ø§Øµ Ø¨Ù†Ø§ØŒ ÙØ¥Ù†Ùƒ ØªÙ…Ù†Ø­ Ù…Ø´Ø§Ø±ÙŠØ¹Ùƒ Ù‚Ø¯Ø±Ø© ÙØ§Ø¦Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‡Ø§Ù… Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù„ØºØ§ØªØŒ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©ØŒ ÙˆØµÙŠØ§ØºØ© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø¯Ù‚Ø© Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ©.</p>
    <p class="mb-6 text-gray-600 dark:text-gray-300">Ø¨ÙØ¶Ù„ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§ØªÙ‡ Ø§Ù„Ø¶Ø®Ù…ØŒ ÙŠØ¸Ù‡Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±ÙˆÙ†Ø© Ø¹Ø§Ù„ÙŠØ© ÙÙŠ Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ Ù…Ø®ØªÙ„Ù Ø§Ù„Ù…Ø¬Ø§Ù„Ø§ØªØŒ Ù…Ù…Ø§ ÙŠØ¶Ù…Ù† Ø¨Ù‚Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚Ø§ØªÙƒ ÙÙŠ Ø·Ù„ÙŠØ¹Ø© Ø«ÙˆØ±Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. ÙŠÙ‚Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¬Ø±Ø¨Ø© Ø³Ù„Ø³Ø© ØªØ¶Ø§Ù‡ÙŠ Ø¬ÙˆØ¯Ø© Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø±Ø§Ø¦Ø¯Ø© Ù…Ø«Ù„ GPT-4oØŒ Ù…Ù…Ø§ ÙŠØ¬Ø¹Ù„Ù‡ Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£Ù…Ø«Ù„ Ù„Ø¨ÙŠØ¦Ø§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø°Ø§Øª Ø§Ù„ÙƒØ«Ø§ÙØ© Ø§Ù„Ø¹Ø§Ù„ÙŠØ© Ø§Ù„ØªÙŠ ØªØªØ·Ù„Ø¨ Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ÙØ§Ø¦Ù‚ ÙƒÙ…Ø¹ÙŠØ§Ø± Ø£Ø³Ø§Ø³ÙŠ.</p>
    <h4 class="text-xl font-bold mb-4 text-primary">Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„ÙÙ†ÙŠØ©:</h4>
    <div class="overflow-x-auto">
        <table class="w-full text-sm text-right border border-gray-200 dark:border-gray-700">
            <thead class="bg-gray-100 dark:bg-gray-800 uppercase font-bold">
                <tr><th class="px-4 py-3">Ø§Ù„Ù…ÙŠØ²Ø©</th><th class="px-4 py-3">Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª</th></tr>
            </thead>
            <tbody class="divide-y divide-gray-200 dark:divide-gray-700">
                <tr><td class="px-4 py-2 font-semibold">Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬</td><td class="px-4 py-2">DeepSeek-V3.2 (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©)</td></tr>
                <tr><td class="px-4 py-2 font-semibold">ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥ØµØ¯Ø§Ø±</td><td class="px-4 py-2">1 Ø¯ÙŠØ³Ù…Ø¨Ø± 2025</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Ø¨Ù†ÙŠØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬</td><td class="px-4 py-2">Multi-head Latent Attention (MLA) & DeepSeekMoE</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª</td><td class="px-4 py-2">671 Ù…Ù„ÙŠØ§Ø± Ù…Ø¹Ø§Ù…Ù„</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©</td><td class="px-4 py-2">37 Ù…Ù„ÙŠØ§Ø± (Ù„ÙƒÙ„ ØªÙˆÙƒÙ†)</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Ù†Ø§ÙØ°Ø© Ø§Ù„Ø³ÙŠØ§Ù‚</td><td class="px-4 py-2">128,000 ØªÙˆÙƒÙ†</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Ø£Ù‚ØµÙ‰ Ø·ÙˆÙ„ Ù„Ù„Ù…Ø®Ø±Ø¬Ø§Øª</td><td class="px-4 py-2">131,072 ØªÙˆÙƒÙ†</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©</td><td class="px-4 py-2">Ø§Ù„Ù†ØµÙˆØµ Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù„ØºØ§ØªØŒ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©ØŒ Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ</td></tr>
                <tr><td class="px-4 py-2 font-semibold">ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©</td><td class="px-4 py-2">ØªÙ‚Ù†ÙŠØ© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ Ù„Ù„ØªÙˆÙƒÙ†Ø§Øª (MTP)</td></tr>
            </tbody>
        </table>
    </div>
</div>

<script type="application/json" id="model-specific-config">
[
    { 
        "id": "stream", "type": "toggle", "val": true,
        "label_en": "Stream Response", 
        "label_ar": "Ø§Ù„Ø¨Ø« Ø§Ù„Ø­ÙŠ (Stream)",
        "desc_en": "Enable: See results instantly. Disable: Wait for full answer.",
        "desc_ar": "ØªÙØ¹ÙŠÙ„: Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹. ØªØ¹Ø·ÙŠÙ„: Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ø±Ø¯."
    },
    { 
        "id": "thinking_mode", "type": "toggle", "val": true,
        "label_en": "Thinking (Reasoning)", 
        "label_ar": "Ù†Ù…Ø· Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚ (Reasoning)",
        "desc_en": "Enable: Use Chain-of-Thought for math/logic. Disable: Faster, direct answer.",
        "desc_ar": "ØªÙØ¹ÙŠÙ„: ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ³Ù„Ø³Ù„ÙŠ Ù„Ø­Ù„ Ø§Ù„Ù…Ø³Ø§Ø¦Ù„ Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©. ØªØ¹Ø·ÙŠÙ„: Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆØ£Ø³Ø±Ø¹."
    },
    { 
        "id": "temperature", "type": "slider", "min": 0, "max": 2, "step": 0.1, "val": 1.3,
        "label_en": "Temperature (Creativity)",
        "label_ar": "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© (Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹)", 
        "desc_en": "High (1.5+): Creative & Random. Low (0.5): Precise & Deterministic.",
        "desc_ar": "Ø¹Ø§Ù„ÙŠØ© (1.5+): Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© ÙˆØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹Ø©. Ù…Ù†Ø®ÙØ¶Ø© (0.5): Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© ÙˆØ§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª."
    },
    { 
        "id": "top_p", "type": "slider", "min": 0, "max": 1, "step": 0.01, "val": 0.9,
        "label_en": "Top P (Diversity)",
        "label_ar": "ØªÙ†ÙˆØ¹ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª (Top P)",
        "desc_en": "High (0.9): Diverse vocabulary. Low (0.1): Common words only.",
        "desc_ar": "Ø¹Ø§Ù„ÙŠØ© (0.9): Ù…ÙØ±Ø¯Ø§Øª Ù…ØªÙ†ÙˆØ¹Ø© ÙˆØºÙ†ÙŠØ©. Ù…Ù†Ø®ÙØ¶Ø© (0.1): ÙŠØ®ØªØ§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹ ÙÙ‚Ø·."
    },
    { 
        "id": "max_tokens", "type": "slider", "min": 1, "max": 8192, "step": 64, "val": 4096,
        "label_en": "Max Tokens",
        "label_ar": "Ø£Ù‚ØµÙ‰ Ø·ÙˆÙ„ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©",
        "desc_en": "Limits the maximum length of the generated response.",
        "desc_ar": "ÙŠØ­Ø¯Ø¯ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª/Ø§Ù„Ø±Ù…ÙˆØ² ÙÙŠ Ø§Ù„Ø±Ø¯ Ø§Ù„ÙˆØ§Ø­Ø¯."
    }
]
</script>
<script>
    // ğŸ”¥ Updated Chat Handler: Simplified (Backend handles retries now)
    window.modelSpecificChatHandler = async function(msg, uiModelId, params, chatBox, loadingDiv, userSignal) {

        const useStream = params.stream;
        const useThinking = params.thinking_mode;

        if(loadingDiv) loadingDiv.remove();

        const botMsgId = `bot-${Date.now()}`;
        const thinkId = `think-${Date.now()}`;

        const botDiv = document.createElement('div');
        botDiv.className = "flex w-full mt-2 space-x-3 max-w-full";

        // Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø±Ø³Ø§Ù„Ø©
        let initialHTML = `<div class="chat-bubble bot" id="${botMsgId}-bubble">`;

        // Ø¥Ø¶Ø§ÙØ© ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„ØªÙÙƒÙŠØ± Ø¯Ø§Ø¦Ù…Ø§Ù‹ ØªØ­Ø³Ø¨Ø§Ù‹ Ù„ÙˆØµÙˆÙ„ ØªØ§Ù‚Ø§Øª ØªÙÙƒÙŠØ± Ù…Ù† Ø§Ù„Ø³ÙŠØ±ÙØ± (Ø³ÙˆØ§Ø¡ Ø·Ù„Ø¨Ù†Ø§Ù‡Ø§ Ø£Ù… Ù„Ø§)
        initialHTML += `
            <div id="think-box-${thinkId}" class="think-box hidden">
                <div class="think-header" onclick="toggleThinkBox('${thinkId}')">
                    <i id="${thinkId}-icon" class="fa-solid fa-circle-notch think-spinner text-primary"></i> 
                    <span id="${thinkId}-label">Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±...</span>
                </div>
                <div id="think-content-${thinkId}" class="think-content hidden-content"></div>
            </div>
        `;

        initialHTML += `<div id="${botMsgId}-text" class="whitespace-pre-wrap"></div></div>`;
        botDiv.innerHTML = initialHTML;
        chatBox.appendChild(botDiv);
        chatBox.scrollTop = chatBox.scrollHeight;

        const thinkBoxEl = document.getElementById(`think-box-${thinkId}`);
        const thinkContentEl = document.getElementById(`think-content-${thinkId}`);
        const textContentEl = document.getElementById(`${botMsgId}-text`);
        const thinkIcon = document.getElementById(`${thinkId}-icon`);
        const thinkLabel = document.getElementById(`${thinkId}-label`);

        let fullThinking = "";
        let fullContent = "";
        let isThinkingFinished = false;

        const finishThinking = () => {
            if(isThinkingFinished || !fullThinking) return;
            isThinkingFinished = true;
            if (thinkIcon) {
                thinkIcon.classList.remove('fa-circle-notch', 'think-spinner', 'text-primary');
                thinkIcon.classList.add('fa-check', 'text-green-500');
            }
            if (thinkLabel) thinkLabel.textContent = "Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙÙƒÙŠØ±";
        };

        const showThinkingBox = () => {
            if (thinkBoxEl && thinkBoxEl.classList.contains('hidden')) {
                thinkBoxEl.classList.remove('hidden');
            }
        };

        try {
            // Ù†Ø±Ø³Ù„ Ø§Ù„Ø·Ù„Ø¨ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·. Ø§Ù„Ø³ÙŠØ±ÙØ± (providers.py) Ø³ÙŠØªÙˆÙ„Ù‰ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØ§Ù„ØªØ¨Ø¯ÙŠÙ„ Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            const currentBody = { 
                message: msg, 
                model_id: uiModelId, 
                ...params,
                // Ù†Ø·Ù„Ø¨ Ø§Ù„ØªÙÙƒÙŠØ± Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø²Ø± Ù…ÙØ¹Ù„Ø§Ù‹ØŒ ÙˆÙ„ÙƒÙ† Ø§Ù„Ø³ÙŠØ±ÙØ± Ù‚Ø¯ ÙŠÙØ±Ø¶Ù‡ Ø¥Ø°Ø§ Ø­ÙˆÙ„ Ù„Ù„Ø·ÙˆØ§Ø±Ø¦
                extra_params: useThinking ? { chat_template_kwargs: { "thinking": true } } : {} 
            };

            const response = await fetch('/api/chat/trial', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify(currentBody),
                signal: userSignal
            });

            if (response.status !== 200) throw new Error(`Status ${response.status}`);

            if (useStream) {
                const reader = response.body.getReader();
                const decoder = new TextDecoder();

                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;

                    const chunk = decoder.decode(value, { stream: true });
                    const lines = chunk.split('\n');

                    for (const line of lines) {
                        if (line.startsWith('data: ')) {
                            const jsonStr = line.slice(6);
                            if (jsonStr === '[DONE]') break;
                            try {
                                const data = JSON.parse(jsonStr);
                                if (data.error) throw new Error(data.error); // Handle Provider Error passed from backend

                                const delta = data.choices[0].delta || {};
                                let content = delta.content || "";
                                let reasoning = delta.reasoning_content || "";

                                // Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªÙÙƒÙŠØ± (Ø³ÙˆØ§Ø¡ Ø¬Ø§Ø¡ Ù…Ù† Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„Ù…Ø®ØµØµ Ø£Ùˆ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ)
                                if (content.includes('<think>')) {
                                    const parts = content.split('<think>');
                                    content = parts[0];
                                    reasoning = parts[1] || "";
                                    showThinkingBox();
                                }
                                if (content.includes('</think>')) {
                                    const parts = content.split('</think>');
                                    reasoning = parts[0]; 
                                    content = parts[1] || "";
                                    finishThinking();
                                }

                                if (reasoning) {
                                    showThinkingBox();
                                    fullThinking += reasoning;
                                    if(thinkContentEl) thinkContentEl.textContent = fullThinking;
                                }

                                if (content) {
                                    // Ø¥Ø°Ø§ ÙˆØµÙ„ Ù…Ø­ØªÙˆÙ‰ØŒ Ù†ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù†ØªÙ‡Ù‰
                                    finishThinking(); 
                                    fullContent += content;
                                    textContentEl.textContent = fullContent;
                                }
                                chatBox.scrollTop = chatBox.scrollHeight;

                            } catch (e) { 
                                console.error("Parse Error or Provider Error", e); 
                                if(e.message && e.message.includes("Provider Error")) {
                                    textContentEl.textContent += `\n[System Error: ${e.message}]`;
                                }
                            }
                        }
                    }
                }
            } else {
                const data = await response.json();
                finishThinking();
                textContentEl.textContent = data.choices ? data.choices[0].message.content : (data.error || "Error");
            }
            finishThinking();

        } catch (err) {
            if (err.name === 'AbortError') {
                // ØªÙ… Ø§Ù„Ø¥Ù„ØºØ§Ø¡ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ù„Ø§ Ù†ÙØ¹Ù„ Ø´ÙŠØ¦Ø§Ù‹ (Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙŠØ¸Ù‡Ø± "ØªÙ… Ø§Ù„Ø¥Ù„ØºØ§Ø¡")
            } else {
                textContentEl.textContent = "Error: " + err.message;
            }
        }
    };
</script>
