<div class="model-lang-content lang-en hidden">
  <h3 class="text-2xl font-bold mb-4">Meta Llama 3.2 3B: Efficiency Meets Intelligence</h3>
  <p class="mb-4 text-gray-600 dark:text-gray-300">Llama 3.2 3B Instruct represents a quantum leap in the lightweight model category. It combines compact size with high cognitive capabilities, making it the premier choice for developers seeking a chatbot engine with instant response times and high linguistic precision. It is ideal for applications requiring continuous, delay-free user interaction.</p>
  <p class="mb-6 text-gray-600 dark:text-gray-300">This model stands out as a strategic solution for managing complex logical tasks, summarization, and creative content generation while maintaining amazing operational efficiency. It outperforms much larger models in context understanding and instruction following.</p>
  <h4 class="text-xl font-bold mb-4 text-primary">Technical Specifications:</h4>
  <div class="overflow-x-auto">
      <table class="w-full text-sm text-left border border-gray-200 dark:border-gray-700">
          <thead class="bg-gray-100 dark:bg-gray-800 uppercase font-bold">
              <tr><th class="px-4 py-3">Feature</th><th class="px-4 py-3">Specification</th></tr>
          </thead>
          <tbody class="divide-y divide-gray-200 dark:divide-gray-700">
              <tr><td class="px-4 py-2 font-semibold">Model Name</td><td class="px-4 py-2">Meta Llama 3.2 3B Instruct</td></tr>
              <tr><td class="px-4 py-2 font-semibold">Release Date</td><td class="px-4 py-2">September 25, 2024</td></tr>
              <tr><td class="px-4 py-2 font-semibold">Category</td><td class="px-4 py-2">Lightweight Advanced LLM</td></tr>
              <tr><td class="px-4 py-2 font-semibold">Context Window</td><td class="px-4 py-2">128,000 Tokens</td></tr>
              <tr><td class="px-4 py-2 font-semibold">Performance</td><td class="px-4 py-2">Superior Instruction Following</td></tr>
              <tr><td class="px-4 py-2 font-semibold">Best Use</td><td class="px-4 py-2">Personal Assistants, Summarization, Automated Support</td></tr>
          </tbody>
      </table>
  </div>
</div>

<div class="model-lang-content lang-ar hidden">
  <h3 class="text-2xl font-bold mb-4">Meta Llama 3.2 3B: Ø¹Ù†Ø¯Ù…Ø§ ØªØ¬ØªÙ…Ø¹ Ø§Ù„Ø³Ø±Ø¹Ø© Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡</h3>
  <p class="mb-4 text-gray-600 dark:text-gray-300">ÙŠÙØ¹Ø¯ Ù†Ù…ÙˆØ°Ø¬ Llama 3.2 3B Instruct Ù‚ÙØ²Ø© Ù†ÙˆØ¹ÙŠØ© ÙÙŠ ÙØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©ØŒ Ø­ÙŠØ« ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† ØµØºØ± Ø§Ù„Ø­Ø¬Ù… ÙˆØ§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ø°Ù‡Ù†ÙŠØ© Ø§Ù„Ø¹Ø§Ù„ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ…ÙŠØ² Ø¹Ø§Ø¦Ù„Ø© Meta. ØªÙ… ØªØ­Ø³ÙŠÙ† Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯Ù‚Ø© Ù„ÙŠÙƒÙˆÙ† Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙˆÙ„ Ù„Ù„Ù…Ø·ÙˆØ±ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠØ¨Ø­Ø«ÙˆÙ† Ø¹Ù† Ù…Ø­Ø±Ùƒ Ù…Ø­Ø§Ø¯Ø«Ø© (Chatbot) ÙŠÙ…ØªØ§Ø² Ø¨Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù„Ø­Ø¸ÙŠØ© ÙˆØ§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ø¹Ø§Ù„ÙŠØ©ØŒ Ù…Ù…Ø§ ÙŠØ¬Ø¹Ù„Ù‡ Ù…Ø«Ø§Ù„ÙŠØ§Ù‹ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„ØªÙŠ ØªØªØ·Ù„Ø¨ ØªÙØ§Ø¹Ù„Ø§Ù‹ Ù…Ø³ØªÙ…Ø±Ø§Ù‹ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¯ÙˆÙ† ØªØ£Ø®ÙŠØ±.</p>
  <p class="mb-6 text-gray-600 dark:text-gray-300">ÙŠØ¨Ø±Ø² Llama 3.2 3B ÙƒØ­Ù„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©ØŒ Ø§Ù„ØªÙ„Ø®ÙŠØµØŒ ÙˆØµÙŠØ§ØºØ© Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©ØŒ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ÙƒÙØ§Ø¡Ø© ØªØ´ØºÙŠÙ„ÙŠØ© Ù…Ø°Ù‡Ù„Ø©. Ø¨ÙØ¶Ù„ ØªØ­Ø³ÙŠÙ†Ø§ØªÙ‡ Ø§Ù„Ø£Ø®ÙŠØ±Ø©ØŒ ÙŠÙ‚Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ø¯Ø§Ø¡Ù‹ ÙŠØªÙÙˆÙ‚ Ø¹Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ Ø£ÙƒØ¨Ø± Ù…Ù†Ù‡ Ø¨ÙƒØ«ÙŠØ± ÙÙŠ ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§ØªØ¨Ø§Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¨Ø¯Ù‚Ø©ØŒ Ù…Ù…Ø§ ÙŠØ¬Ø¹Ù„Ù‡ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£ÙƒØ«Ø± Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© ÙˆØªÙˆØ§Ø²Ù†Ø§Ù‹ ÙÙŠ Ù…Ù†ØµØªÙ†Ø§ Ù„Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„ØªÙŠ ØªØ³ØªÙ‡Ø¯Ù Ø§Ù„Ø¬Ù…Ø¹ Ø¨ÙŠÙ† ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø³Ù„Ø³Ø© ÙˆØ§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ø°ÙƒÙŠØ©.</p>
  <h4 class="text-xl font-bold mb-4 text-primary">Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„ÙÙ†ÙŠØ©:</h4>
  <div class="overflow-x-auto">
      <table class="w-full text-sm text-right border border-gray-200 dark:border-gray-700">
          <thead class="bg-gray-100 dark:bg-gray-800 uppercase font-bold">
              <tr><th class="px-4 py-3">Ø§Ù„Ù…ÙŠØ²Ø©</th><th class="px-4 py-3">Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª</th></tr>
          </thead>
          <tbody class="divide-y divide-gray-200 dark:divide-gray-700">
              <tr><td class="px-4 py-2 font-semibold">Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬</td><td class="px-4 py-2">Meta Llama 3.2 3B Instruct</td></tr>
              <tr><td class="px-4 py-2 font-semibold">ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥ØµØ¯Ø§Ø±</td><td class="px-4 py-2">25 Ø³Ø¨ØªÙ…Ø¨Ø± 2024</td></tr>
              <tr><td class="px-4 py-2 font-semibold">Ø§Ù„ØªØµÙ†ÙŠÙ</td><td class="px-4 py-2">Ù†Ù…ÙˆØ°Ø¬ Ù„ØºÙˆÙŠ Ù…ØªØ·ÙˆØ± ÙØ¦Ø© Lightweight</td></tr>
              <tr><td class="px-4 py-2 font-semibold">Ù†Ø§ÙØ°Ø© Ø§Ù„Ø³ÙŠØ§Ù‚</td><td class="px-4 py-2">128,000 ØªÙˆÙƒÙ†</td></tr>
              <tr><td class="px-4 py-2 font-semibold">Ù†Ù…Ø· Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©</td><td class="px-4 py-2">Ù†ØµÙˆØµ (Text-to-Text)</td></tr>
              <tr><td class="px-4 py-2 font-semibold">Ù‚ÙˆØ© Ø§Ù„Ø£Ø¯Ø§Ø¡</td><td class="px-4 py-2">Ù…ØªÙÙˆÙ‚ ÙÙŠ Ø§ØªØ¨Ø§Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª (Instruction Following)</td></tr>
              <tr><td class="px-4 py-2 font-semibold">Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù…Ø«Ù„</td><td class="px-4 py-2">Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©ØŒ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆØ¯Ø¹Ù… Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ø¤ØªÙ…Øª</td></tr>
          </tbody>
      </table>
  </div>
</div>
<script type="application/json" id="model-specific-config">
[
    { 
        "id": "stream", "type": "toggle", "val": true,
        "label_en": "Stream Response", "label_ar": "Ø§Ù„Ø¨Ø« Ø§Ù„Ø­ÙŠ (Stream)",
        "desc_en": "Enable: Instant text flow.", "desc_ar": "ØªÙØ¹ÙŠÙ„: ØªØ¯ÙÙ‚ Ø§Ù„Ù†Øµ ÙÙˆØ±ÙŠØ§Ù‹."
    },
    { 
        "id": "temperature", "type": "slider", "min": 0, "max": 1, "step": 0.01, "val": 0.2,
        "label_en": "Temperature", "label_ar": "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©",
        "desc_en": "Keep low (0.2) for instruction following.",
        "desc_ar": "ÙŠÙØ¶Ù„ Ø¥Ø¨Ù‚Ø§Ø¤Ù‡Ø§ Ù…Ù†Ø®ÙØ¶Ø© (0.2) Ù„Ø¶Ù…Ø§Ù† Ø§ØªØ¨Ø§Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¨Ø¯Ù‚Ø©."
    },
    { 
        "id": "max_tokens", "type": "slider", "min": 1, "max": 4096, "step": 1, "val": 1024,
        "label_en": "Max Tokens", "label_ar": "Ø£Ù‚ØµÙ‰ Ø·ÙˆÙ„ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©",
        "desc_en": "Limit response length.", "desc_ar": "ØªØ­Ø¯ÙŠØ¯ Ø·ÙˆÙ„ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…ÙˆÙ„Ø¯."
    }
]
</script>
<script>
    // ğŸ”¥ Updated to accept 'userSignal'
    window.modelSpecificChatHandler = async function(msg, uiModelId, params, chatBox, loadingDiv, userSignal) {
        const useStream = params.stream;
        if(loadingDiv) loadingDiv.remove();

        const botMsgId = `bot-${Date.now()}`;
        const botDiv = document.createElement('div');
        botDiv.className = "flex w-full mt-2 space-x-3 max-w-full";
        botDiv.innerHTML = `<div class="chat-bubble bot" id="${botMsgId}"></div>`;
        chatBox.appendChild(botDiv);
        const textEl = document.getElementById(botMsgId);

        const body = { message: msg, model_id: uiModelId, ...params };

        // ğŸ”¥ Pass signal
        const response = await fetch('/api/chat', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify(body),
            signal: userSignal
        });

        if (useStream && response.body) {
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                const chunk = decoder.decode(value);
                const lines = chunk.split('\n');
                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const jsonStr = line.slice(6);
                        if (jsonStr === '[DONE]') break;
                        try {
                            const data = JSON.parse(jsonStr);
                            const content = data.choices[0].delta.content || "";
                            textEl.textContent += content;
                            chatBox.scrollTop = chatBox.scrollHeight;
                        } catch(e){}
                    }
                }
            }
        } else {
            const data = await response.json();
            textEl.textContent = data.choices[0].message.content;
        }
    };
</script>