<div class="model-lang-content lang-en hidden">
    <h3 class="text-2xl font-bold mb-4">Gemma 3 4B-IT: Next-Gen Speed & Efficiency</h3>
    <p class="mb-4 text-gray-600 dark:text-gray-300">Gemma 3 4B-IT is Google's latest innovation in high-efficiency AI. Designed specifically for developers prioritizing "speed" and "instant response," its advanced architecture delivers stunning performance in multilingual tasks and multimodal processing. It is the perfect engine for building lightning-fast chatbots and digital assistants at very low operational costs.</p>
    <p class="mb-6 text-gray-600 dark:text-gray-300">Distinctive for its ability to handle massive contexts up to 128,000 tokens with the lowest latency in its class. Whether for customer service, visual data extraction, or complex dialogue management, Gemma 3 provides the perfect balance of practical intelligence and resource economy.</p>
    <h4 class="text-xl font-bold mb-4 text-primary">Technical Specifications:</h4>
    <div class="overflow-x-auto">
        <table class="w-full text-sm text-left border border-gray-200 dark:border-gray-700">
            <thead class="bg-gray-100 dark:bg-gray-800 uppercase font-bold">
                <tr><th class="px-4 py-3">Feature</th><th class="px-4 py-3">Specification</th></tr>
            </thead>
            <tbody class="divide-y divide-gray-200 dark:divide-gray-700">
                <tr><td class="px-4 py-2 font-semibold">Model Name</td><td class="px-4 py-2">Google Gemma 3 4B-IT (Enhanced)</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Release Date</td><td class="px-4 py-2">March 11, 2025</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Category</td><td class="px-4 py-2">Multimodal Intelligent Model</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Context Window</td><td class="px-4 py-2">128,000 Tokens</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Modalities</td><td class="px-4 py-2">Text, Images, Visual Documents</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Latency</td><td class="px-4 py-2">Ultra-low (Real-time optimized)</td></tr>
            </tbody>
        </table>
    </div>
</div>

<div class="model-lang-content lang-ar hidden">
    <h3 class="text-2xl font-bold mb-4">Gemma 3 4B-IT: Ø³Ø±Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù‚ØµÙˆÙ‰</h3>
    <p class="mb-4 text-gray-600 dark:text-gray-300">ÙŠÙÙ…Ø«Ù„ Gemma 3 4B-IT Ø§Ù„Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø« Ù…Ù† Ø§Ø¨ØªÙƒØ§Ø±Ø§Øª Google ÙÙŠ Ø¹Ø§Ù„Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„ÙƒÙØ§Ø¡Ø©. ØªÙ… ØªØµÙ…ÙŠÙ… Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø®ØµÙŠØµØ§Ù‹ Ù„Ù„Ù…Ø·ÙˆØ±ÙŠÙ† ÙˆØ§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„ØªÙŠ ØªØ¶Ø¹ "Ø§Ù„Ø³Ø±Ø¹Ø©" Ùˆ"Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù„Ø­Ø¸ÙŠØ©" ÙƒØ£ÙˆÙ„ÙˆÙŠØ© Ù‚ØµÙˆÙ‰ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚Ø§ØªÙ‡Ø§. Ø¨ÙØ¶Ù„ Ø¨Ù†ÙŠØªÙ‡ Ø§Ù„Ù…ØªØ·ÙˆØ±Ø©ØŒ ÙŠÙ‚Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ø¯Ø§Ø¡Ù‹ Ù…Ø°Ù‡Ù„Ø§Ù‹ ÙÙŠ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ© (Multimodal)ØŒ Ù…Ù…Ø§ ÙŠØ¬Ø¹Ù„Ù‡ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ Ù„Ø¨Ù†Ø§Ø¡ Ø±ÙˆØ¨ÙˆØªØ§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø°ÙƒÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§Ø¹Ø¯ÙŠÙ† Ø§Ù„Ø±Ù‚Ù…ÙŠÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠØªÙØ§Ø¹Ù„ÙˆÙ† Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ø³Ø±Ø¹Ø© Ø§Ù„Ø¨Ø±Ù‚ ÙˆØ¨ØªÙƒÙ„ÙØ© ØªØ´ØºÙŠÙ„ÙŠØ© Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ø§Ù‹.</p>
    <p class="mb-6 text-gray-600 dark:text-gray-300">Ù…Ø§ ÙŠÙ…ÙŠØ² Gemma 3 4B-IT ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ù‡Ùˆ Ù‚Ø¯Ø±ØªÙ‡ Ø§Ù„ÙØ§Ø¦Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³ÙŠØ§Ù‚Ø§Øª Ø¶Ø®Ù…Ø© ØªØµÙ„ Ø¥Ù„Ù‰ 128,000 ØªÙˆÙƒÙ†ØŒ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø²Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© (Latency) Ù‡Ùˆ Ø§Ù„Ø£Ù‚Ù„ ÙÙŠ ÙØ¦ØªÙ‡. Ø³ÙˆØ§Ø¡ ÙƒÙ†Øª ØªØ±ØºØ¨ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ù†Ø¸Ø§Ù… Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ØŒ Ø£Ùˆ Ø£Ø¯Ø§Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù…Ø³ØªÙ†Ø¯Ø§ØªØŒ Ø£Ùˆ Ù…Ø­Ø±ÙƒØ§Ù‹ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­ÙˆØ§Ø±Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©ØŒ ÙØ¥Ù† Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠÙˆÙØ± Ù„Ùƒ Ø§Ù„ØªÙˆØ§Ø²Ù† Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ ÙˆØ§Ù„Ø§Ù‚ØªØµØ§Ø¯ ÙÙŠ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯.</p>
    <h4 class="text-xl font-bold mb-4 text-primary">Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„ÙÙ†ÙŠØ©:</h4>
    <div class="overflow-x-auto">
        <table class="w-full text-sm text-right border border-gray-200 dark:border-gray-700">
            <thead class="bg-gray-100 dark:bg-gray-800 uppercase font-bold">
                <tr><th class="px-4 py-3">Ø§Ù„Ù…ÙŠØ²Ø©</th><th class="px-4 py-3">Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª</th></tr>
            </thead>
            <tbody class="divide-y divide-gray-200 dark:divide-gray-700">
                <tr><td class="px-4 py-2 font-semibold">Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬</td><td class="px-4 py-2">Google Gemma 3 4B-IT (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø·ÙˆØ±Ø©)</td></tr>
                <tr><td class="px-4 py-2 font-semibold">ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥ØµØ¯Ø§Ø±</td><td class="px-4 py-2">11 Ù…Ø§Ø±Ø³ 2025</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Ø§Ù„ØªØµÙ†ÙŠÙ</td><td class="px-4 py-2">Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒÙŠ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· (Multimodal)</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Ù†Ø§ÙØ°Ø© Ø§Ù„Ø³ÙŠØ§Ù‚</td><td class="px-4 py-2">128,000 ØªÙˆÙƒÙ†</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©</td><td class="px-4 py-2">Ø§Ù„Ù†ØµÙˆØµØŒ Ø§Ù„ØµÙˆØ±ØŒ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ©</td></tr>
                <tr><td class="px-4 py-2 font-semibold">Ø³Ø±Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©</td><td class="px-4 py-2">ÙØ§Ø¦Ù‚Ø© (Optimized for Real-time apps)</td></tr>
            </tbody>
        </table>
    </div>
</div>

<script type="application/json" id="model-specific-config">
[
    { 
        "id": "stream", "type": "toggle", "val": true,
        "label_en": "Stream Response", "label_ar": "Ø§Ù„Ø¨Ø« Ø§Ù„Ø­ÙŠ (Stream)",
        "desc_en": "Enable: Instant text flow.", "desc_ar": "ØªÙØ¹ÙŠÙ„: ØªØ¯ÙÙ‚ Ø§Ù„Ù†Øµ ÙÙˆØ±ÙŠØ§Ù‹."
    },
    { 
        "id": "temperature", "type": "slider", "min": 0, "max": 1, "step": 0.01, "val": 0.2,
        "label_en": "Temperature", "label_ar": "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©",
        "desc_en": "Controls randomness.", "desc_ar": "Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©."
    },
    { 
        "id": "max_tokens", "type": "slider", "min": 1, "max": 8192, "step": 1, "val": 2048,
        "label_en": "Max Tokens", "label_ar": "Ø£Ù‚ØµÙ‰ Ø·ÙˆÙ„ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©",
        "desc_en": "Limit response length.", "desc_ar": "ØªØ­Ø¯ÙŠØ¯ Ø·ÙˆÙ„ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…ÙˆÙ„Ø¯."
    }
]
</script>
<div class="model-lang-content lang-en hidden">
    <h3 class="text-2xl font-bold mb-4">Gemma 3 4B-IT: Next-Gen Speed</h3>
    </div>
<div class="model-lang-content lang-ar hidden">
    <h3 class="text-2xl font-bold mb-4">Gemma 3 4B-IT: Ø³Ø±Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù‚ØµÙˆÙ‰</h3>
    </div>

<script type="application/json" id="model-specific-config">
[
    { "id": "stream", "type": "toggle", "val": true, "label_en": "Stream", "label_ar": "Ø¨Ø« Ø­ÙŠ" },
    { "id": "temperature", "type": "slider", "min": 0, "max": 1, "val": 0.2, "label_en": "Temperature", "label_ar": "Ø§Ù„Ø­Ø±Ø§Ø±Ø©" }
]
</script>
<script>
    // ğŸ”¥ Updated to accept 'userSignal'
    window.modelSpecificChatHandler = async function(msg, uiModelId, params, chatBox, loadingDiv, userSignal) {
        const useStream = params.stream;
        if(loadingDiv) loadingDiv.remove();

        const botMsgId = `bot-${Date.now()}`;
        const botDiv = document.createElement('div');
        botDiv.className = "flex w-full mt-2 space-x-3 max-w-full";
        botDiv.innerHTML = `<div class="chat-bubble bot" id="${botMsgId}"></div>`;
        chatBox.appendChild(botDiv);
        const textEl = document.getElementById(botMsgId);

        const body = { message: msg, model_id: uiModelId, ...params };

        // ğŸ”¥ Pass signal
        const response = await fetch('/api/chat', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify(body),
            signal: userSignal
        });

        if (useStream && response.body) {
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                const chunk = decoder.decode(value);
                const lines = chunk.split('\n');
                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const jsonStr = line.slice(6);
                        if (jsonStr === '[DONE]') break;
                        try {
                            const data = JSON.parse(jsonStr);
                            const content = data.choices[0].delta.content || "";
                            textEl.textContent += content;
                            chatBox.scrollTop = chatBox.scrollHeight;
                        } catch(e){}
                    }
                }
            }
        } else {
            const data = await response.json();
            textEl.textContent = data.choices[0].message.content;
        }
    };
</script>